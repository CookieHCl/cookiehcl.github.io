---
title: 딥기 Lec 14
categories:
  - SNU
  - 4-1
  - 딥러닝의 기초
date: 2023-04-27 12:32:22
tags:
---

# Autoregressive models

image x의 likelihood를 $p(x) = \prod_{i=1}^{n^2} p(x_i \vert x_1, \ldots, x_{i-1})$라고 정의함

즉, 각 pixel은 이전 pixel들의 conditional distribution

픽셀 순서는 그냥 row by row

실제 이미지는 RGB라 색깔별로 또 conditional distribution

$$p(x_i \vert x_{<i}) = p(x_{i,R} \vert x_{<i})p(x_{i,G} \vert x_{<i},x_{i,R})p(x_{i,B} \vert x_{<i},x_{i,R},x_{i,G})$$

## PixelRNN

이거 완전 RNN 아니냐? RNN을 사용해서 구현

근데 이미지는 n^2^개의 pixel이라 무지성 RNN은 오래 걸리고 Row LSTM Diagonal LSTM 같은 뭐 복잡한게 있다고 함

여기선 무시하고 아래 CNN 사용

## PixelCNN

![PixelCNN](pixel_cnn.png)

CNN with large receptive field으로 구현, 이전 pixel들의 conditional distribution이므로 아직 안 나온 pixel들은 무시

$$\max_\theta \mathbb{E}_{x \sim \mathcal{D}_{train}} \left[ p_\theta(x) \coloneqq \prod_{i=1}^{n^2} p_\theta(x_i \vert x_{<i}) \right]$$

훈련은 위에처럼 하면 CNN이라 빠르지만 generate는 픽셀 하나하나 generate해야 해서 똑같이 느림

VAE와 달리 $p_\theta(x)$를 직접적으로 구할 수 있음! VAE는 구한 이미지의 퀄리티를 알 수 없어서 Inception score 같은걸로 측정했지만 Autoregressive model은 구한 이미지의 퀄리티를 수치로 나타낼 수 있음

# Generative Adversarial Networks (GAN)

VAE는 $p_\theta(x) = \int p(z)p_\theta(x \vert z) dz$를 구하려고 했지만, 구할 수 없어서 (적분 analytically하게 못 구함) 대신 ELBO 같은걸 사용했었음

density function 어려움 -> GAN에선 그냥 포기

game-theory처럼 두 플레이어가 서로 경쟁하도록 만듦!

![GAN](gan.png)

Generator network
: random noise로부터 진짜같은 이미지를 만들어서 discriminator를 속이려고 함

Discriminator network
: 진짜 이미지인지 만들어진 이미지인지 구분함 (진짜면 1 아니면 0)

$$\min_{\theta_g}\max_{\theta_d} \mathbb{E}_{x \sim p_{data}} \left[ \log D_{\theta_d}(x) \right] + \mathbb{E}_{z \sim p(z)} \left[ \log (1 - D_{\theta_d}(G_{\theta_g}(z))) \right]$$

minmax game처럼 작동! 앞쪽은 discriminator가 실제 data는 최대한 1을 만들려고 함, 뒤쪽은 discriminator는 가짜 data는 최대한 0을 만들려고 함, generator는 discriminator가 최대한 1을 내놓도록 만들려고 함

## Training of GAN

Gradient ascent on discriminator

$$\max_{\theta_d} \mathbb{E}_{x \sim p_{data}} \left[ \log D_{\theta_d}(x) \right] + \mathbb{E}_{z \sim p(z)} \left[ \log (1 - D_{\theta_d}(G_{\theta_g}(z))) \right]$$

Gradient descent on generator

$$\min_{\theta_g}\mathbb{E}_{z \sim p(z)} \left[ \log (1 - D_{\theta_d}(G_{\theta_g}(z))) \right]$$

이걸 번갈아서 반복!

문제점: discriminator가 너무 멍청하면 generator가 아무거나 만들거고 discriminator가 너무 완벽하면 gradient가 0이라 generator가 포기함 -> 훈련하기 매우 어려운 네트워크임, 적절하게 둘 다 훈련시켜야 함

![GAN training](gan_training.png)

문제점2: generator는 초반에 매우 안 좋음 -> discriminator가 0으로 내놓음  
근데 $\log(1-x)$는 0 근처에서 gradient가 거의 0이라서 훈련이 안 됨!

그래서 실제로는 아래 식으로 Gradient ascent on generator를 해서 초반에 훈련이 잘 되고 discriminator를 잘 속일 때 훈련이 덜 되도록 만듦

$$\max_{\theta_g}\mathbb{E}_{z \sim p(z)} \left[ \log (D_{\theta_d}(G_{\theta_g}(z))) \right]$$

모든게 끝나면 generator만 따로 가져와서 쓰면 됨!

## Optimal discriminator and generator

G가 고정일 때 Optimal discriminator는 $D_G^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$

Let $V(G,D)=\mathbb{E}_{x \sim p_{data}} \left[ \log (D(x)) \right] + \mathbb{E}_{z \sim p(z)} \left[ \log (1 - D(G(z))) \right]$ (여담: V는 value function, 게임이론에서 이름 따옴)

$$
\begin{align*}
  V(G,D) &= \int_x p_{data}(x)\log(D(x))dx + \int_z p(z)\log(1 - D(G(z)))dz\\
  &= \int_x p_{data}(x)\log(D(x))dx + \int_x p(z)\log(1 - D(x)) \lvert \frac{\partial z}{\partial x} \rvert dx\\
  &= \int_x p_{data}(x)\log(D(x))dx + \int_x p_g(x) \lvert \frac{\partial x}{\partial z} \rvert \log(1 - D(x)) \lvert \frac{\partial z}{\partial x} \rvert dx\\
  &= \int_x p_{data}(x)\log(D(x)) + p_g(x)\log(1 - D(x))dx\\
\end{align*}
$$

$a\log(y) + b\log(1-y)$는 $y \in [0,1]$에서 최댓값을 $y=\frac{a}{a+b}$일 떄 가지므로, optimal discriminator는 $D_G^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$

이때 training criterion을 C(G)로 나타내면

$$
\begin{align*}
  C(G) &= \max_{D} V(G, D)\\
  &= \mathbb{E}_{x \sim p_{data}} \left[ \log D_G^*(x) \right] + \mathbb{E}_{z \sim p_z} \left[ \log (1 - D_G^*(G(z))) \right]\\
  &= \mathbb{E}_{x \sim p_{data}} \left[ \log D_G^*(x) \right] + \mathbb{E}_{x \sim p_g} \left[ \log (1 - D_G^*(x)) \right]\\
  &= \mathbb{E}_{x \sim p_{data}} \left[ \log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \right] + \mathbb{E}_{x \sim p_g} \left[ \log \frac{p_g(x)}{p_{data}(x) + p_g(x)} \right]\\
  &= -\log(4) + D_{KL}\left( p_{data} \Vert \frac{p_{data} + p_g}{2} \right) + D_{KL}\left( p_g \Vert \frac{p_{data} + p_g}{2} \right)\\
  &= -\log(4) + 2JSD(p_{data} \Vert p_g) \geq -\log(4)
\end{align*}
$$

JSD는 두 probability distribution이 같을 때만 최솟값 0을 가지므로, Optimal generator는 $p_g = p_{data}$

## Deep Convolution GAN (DCGAN)

FC 없이 CNN으로만 + pooling 없이 stride CNN으로만 + batch norm + ReLU in generator (마지막 output은 tanh), Leaky ReLU in discriminator

이렇게 만들고 무지성 layer 폭격 -> 개잘됨!

## GAN vector

Z vector들로 vector 연산이 가능함 (ex: 안경 쓴 여자를 만드는 z - 안경 안 쓴 여자를 만드는 z + 안경 안 쓴 남자를 만드는 z = 안경 쓴 남자를 만드는 z)

여담) 요즘 Diffusion model에 밀리긴 했지만 사실 Diffusion model 만들 때 이미지를 더 많이 넣어서 그럼; GAN에도 그만큼 이미지 넣으면 잘 나옴
