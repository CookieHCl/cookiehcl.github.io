---
title: 자연언어처리 Lec 11
categories:
  - SNU
  - 4-1
  - 자연언어처리개론
date: 2023-04-18 15:31:04
tags:
---

# Beam search

beam size만큼 가장 확률이 높은 문장들을 저장하고, beam에 있는 문장마다 뒤에 단어를 덧붙임

END 토큰이 나올 경우 완성된걸로 치고 따로 빼둠

timestamp T까지 계속하거나(최대 단어 수) 완성된 문장들이 n개가 될 때까지 계속함

# BLEU (Bilingual Evaluation Understudy)

기계번역을 여러 휴ㅡ먼 번역과 비교해서 n-gram으로 similarity score를 줌

# Attention

- NMT 성능 개사기
- bottleneck 문제 해결 (기존 RNN에서 문장을 1개의 vector로 나타내니까 마지막 단어만 너무 중요해짐)
- vanishing gradient 문제 해결 (비슷한 문제, 비슷한 해결책)
- interpretability (attention distribution을 보고 alignment 분석 가능)

Translate 말고도 vector value들이 있을 때 query에 따라 weighted sum of value를 얻고 싶을 때 사용

# GPT

그냥 계속 다음 단어를 예측하도록 만듦; 문장이나 단락이 끝나면 거기서 끝

근데 왜 이렇게 좋아짐? 그냥 parameter를 무지막지하게 박음....

but user instruction 지키는건 잘 못 함

## Supervised Fine Tuning(SFT)

사람들이 직접 좋은 답변들만 적어주고 그걸로 훈련

## Reinforcement Learning from Human Feedback

전부 SFT로 훈련시키기엔 너무 비쌈

SFT로 훈련된 GPT가 여러 답변들을 생성하게 하고 랭킹을 매기자!
